{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performPCA(X,Y):\n",
    "    \n",
    "    # Splitting the dataset into the Training set and Test set\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)\n",
    "    \n",
    "    # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    # Applying PCA\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components = 2)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    \n",
    "    split_data = [X_train, X_test, Y_train, Y_test]\n",
    "    \n",
    "    print(\"The Variance is\",explained_variance)\n",
    "    return split_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyModel(split_data):\n",
    "    \n",
    "    X_train = split_data[0]\n",
    "    X_test = split_data[1]\n",
    "    Y_train = split_data[2]\n",
    "    Y_test = split_data[3]\n",
    "\n",
    "    # Fitting Logistic Regression to the Training set\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    classifier = LogisticRegression(random_state = 0)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    #Get Accuracy Score\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(\"\")\n",
    "    print(\"Accuracy:\",accuracy_score(Y_test,y_pred))\n",
    "    print(\"\")\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    return classifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyModelNB(split_data):\n",
    "    \n",
    "    X_train = split_data[0]\n",
    "    X_test = split_data[1]\n",
    "    Y_train = split_data[2]\n",
    "    Y_test = split_data[3]\n",
    "\n",
    "    # Fitting Logistic Regression to the Training set\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    #Get Accuracy Score\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print (\"Accuracy:\",accuracy_score(Y_test,y_pred))\n",
    "    print(\"\")\n",
    "    \n",
    "    from sklearn import metrics\n",
    "    precision = metrics.precision_score(Y_test,y_pred)\n",
    "    print(\"Precision is----\")\n",
    "    print(precision)\n",
    "    print(\"\")    \n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfusionMatrix(X_test,Y_test,classifier):\n",
    "    \n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm = confusion_matrix(Y_test, y_pred)\n",
    "    print(\"Confusion Matrix is as follows\")\n",
    "    print(cm)\n",
    "    print(\"\")\n",
    "    \n",
    "    if(cm.shape == (2,2)):\n",
    "        TP = cm[1, 1]\n",
    "        TN = cm[0, 0]\n",
    "        FP = cm[0, 1]\n",
    "        FN = cm[1, 0]\n",
    "\n",
    "        from sklearn import metrics\n",
    "\n",
    "        # calculate classification error\n",
    "        classification_error = 1 - metrics.accuracy_score(Y_test, y_pred)\n",
    "        print(\"Classification Error\")\n",
    "        print(classification_error)\n",
    "        print(\"\")\n",
    "\n",
    "        # calculate Sensitivity or Recall\n",
    "        sensitivity = metrics.recall_score(Y_test, y_pred)\n",
    "        print(\"Sensitivity or Recall\")\n",
    "        print(sensitivity)\n",
    "        print(\"\")\n",
    "\n",
    "        # calculate Specificity \n",
    "        specificity = TN / (TN + FP)\n",
    "        print(\"Specificity\")\n",
    "        print(specificity)\n",
    "        print(\"\")\n",
    "\n",
    "        # calculate False Positive Rate \n",
    "        false_positive_rate = 1 - specificity\n",
    "        print(\"False Positive Rate\")\n",
    "        print(false_positive_rate)\n",
    "        print(\"\")    \n",
    "\n",
    "        # calculate Precision \n",
    "        #precision = TP / float(TP + FP)\n",
    "        precision = metrics.precision_score(Y_test, y_pred)\n",
    "        print(\"Precision\")\n",
    "        print(precision)\n",
    "        print(\"\")    \n",
    "    else:\n",
    "        print(\"Cannot Calculate metrics from 3X3 confusion matrix\")\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    return cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetrics(confusion):\n",
    "    \n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "\n",
    "    from sklearn import metrics\n",
    "    \n",
    "    # calculate classification error\n",
    "    classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "    print(\"Classification Error\")\n",
    "    print(classification_error)\n",
    "    print(\"\")\n",
    "    \n",
    "    # calculate Sensitivity or Recall\n",
    "    sensitivity = TP / float(FN + TP)\n",
    "    print(\"Sensitivity or Recall\")\n",
    "    print(sensitivity)\n",
    "    print(\"\")\n",
    "    \n",
    "    # calculate Specificity \n",
    "    specificity = TN / (TN + FP)\n",
    "    print(\"Specificity\")\n",
    "    print(specificity)\n",
    "    print(\"\")\n",
    "    \n",
    "    # calculate False Positive Rate \n",
    "    false_positive_rate = FP / float(TN + FP)\n",
    "    print(\"False Positive Rate\")\n",
    "    print(false_positive_rate)\n",
    "    print(\"\")    \n",
    " \n",
    "    # calculate Precision \n",
    "    #precision = TP / float(TP + FP)\n",
    "    precision = metrics.precision_score(y_test, y_pred_class)\n",
    "    print(\"Precision\")\n",
    "    print(precision)\n",
    "    print(\"\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfusionMatrixNB(split_data):\n",
    "    \n",
    "    X_train = split_data[0]\n",
    "    X_test = split_data[1]\n",
    "    Y_train = split_data[2]\n",
    "    Y_test = split_data[3]\n",
    "\n",
    "    # Fitting Naive Bayes to the Training set\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    #Get Accuracy Score\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print (\"Accuracy:\",accuracy_score(Y_test,y_pred))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(Y_test, y_pred)\n",
    "    print(\"Confusion Matrix is as follows\")\n",
    "    print(cm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXTrain(split_data):\n",
    "    return split_data[0]\n",
    "\n",
    "def getXTest(split_data):\n",
    "    return split_data[1]\n",
    "\n",
    "def getYTrain(split_data):\n",
    "    return split_data[2]\n",
    "\n",
    "def getYTest(split_data):\n",
    "    return split_data[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "def getVisuals(X,Y,classifier,title):\n",
    "        X_set, y_set = X, Y\n",
    "        X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                             np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "        plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "                     alpha = 0.5, cmap = ListedColormap(('red', 'green')))\n",
    "        plt.xlim(X1.min(), X1.max())\n",
    "        plt.ylim(X2.min(), X2.max())\n",
    "        for i, j in enumerate(np.unique(y_set)):\n",
    "            plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                        c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Actual Crime Rate')\n",
    "        plt.ylabel('Predicted Crime Rate')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
